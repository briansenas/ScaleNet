{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, current_dir)\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "from models.model_RCNN_only import RCNN_only\n",
    "from maskrcnn_rui.data.transforms import build_transforms_maskrcnn\n",
    "\n",
    "from maskrcnn_rui.config import cfg\n",
    "\n",
    "import utils.model_utils as model_utils\n",
    "from utils.logger import setup_logger, printer\n",
    "from utils.train_utils import *\n",
    "from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n",
    "from utils.checkpointer import DetectronCheckpointer\n",
    "\n",
    "\n",
    "from utils.utils_misc import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Rui's Scale Estimation Network Training\")\n",
    "# Training\n",
    "parser.add_argument('--task_name', type=str, default='tmp', help='resume training')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=8)\n",
    "parser.add_argument('--batchsize', type=int, default=36, help='input batch size during training')\n",
    "parser.add_argument('--save_every_iter', type=int, default=0, help='set to 0 to save ONLY at the end of each epoch')\n",
    "# parser.add_argument('--batchsizeeval', type=int, default=42, help='input batch size during evaluation')\n",
    "parser.add_argument('--niter', type=int, default=5000, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate, default=0.005')\n",
    "parser.add_argument('--beta1', type=float, default=0.9, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--not_val', action='store_true', help='Do not validate duruign training')\n",
    "parser.add_argument('--save_every_epoch', type=int, default=10, help='save checkpoint every ? epoch')\n",
    "# Model\n",
    "parser.add_argument('--accu_model', action='store_true', help='Use accurate model with theta instead of Derek\\'s approx.')\n",
    "# Pretraining\n",
    "parser.add_argument('--resume', type=str, help='resume training; can be full path (e.g. tmp/checkpoint0.pth.tar) or taskname (e.g. tmp)', default='NoCkpt')\n",
    "parser.add_argument('--feature_only', action='store_true', help='restore only features (remove all classifiers) from checkpoint')\n",
    "# Device\n",
    "parser.add_argument('--cpu', action='store_true', help='Force training on CPU')\n",
    "parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "parser.add_argument(\"--master_port\", type=str, default='8914')\n",
    "# DEBUG\n",
    "parser.add_argument('--debug', action='store_true', help='Debug eval')\n",
    "# Mask R-CNN\n",
    "parser.add_argument('--not_rcnn', action='store_true', help='Disable Mask R-CNN module')\n",
    "\n",
    "parser.add_argument('--pointnet_camH', action='store_true', help='')\n",
    "parser.add_argument('--est_bbox', action='store_true', help='Enable estimating bboxes instead of using GT bboxes')\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--config-file\",\n",
    "    default=\"\",\n",
    "    metavar=\"FILE\",\n",
    "    help=\"path to config file\",\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"opts\",\n",
    "    help=\"Modify config options using the command-line\",\n",
    "    default=None,\n",
    "    nargs=argparse.REMAINDER,\n",
    ")\n",
    "\n",
    "# opt = parser.parse_args()\n",
    "opt = parser.parse_args('--batchsize=1 --task_name tmp_eval --niter 1 --accu_model --resume YES \\\n",
    "--config-file coco_config_small_RCNNOnly.yaml \\\n",
    "SOLVER.IMS_PER_BATCH 1 TEST.IMS_PER_BATCH 1'.split())\n",
    "\n",
    "opt.checkpoints_folder = 'checkpoint'\n",
    "\n",
    "# config_file = \"maskrcnn/coco_config.yaml\"\n",
    "config_file = opt.config_file\n",
    "cfg.merge_from_file(config_file)\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cuda\"])\n",
    "cfg.merge_from_list(opt.opts)\n",
    "cfg.freeze()\n",
    "opt.cfg = cfg\n",
    "\n",
    "# === DISTRIBUTED TRAINING\n",
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "opt.distributed = num_gpus > 1\n",
    "if opt.distributed:\n",
    "    torch.cuda.set_device(opt.local_rank)\n",
    "    torch.distributed.init_process_group(\n",
    "        backend=\"nccl\", init_method=\"env://\"\n",
    "    )\n",
    "    synchronize()\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() and not opt.cpu else \"cpu\")\n",
    "device = 'cuda'\n",
    "print(\"Device:\", device)\n",
    "rank = get_rank()\n",
    "\n",
    "# === SUMMARY WRITERS\n",
    "summary_path = './summary/'+opt.task_name\n",
    "writer = SummaryWriter(summary_path)\n",
    "\n",
    "# === LOGGING\n",
    "# sys.stdout = Logger(summary_path+'/log.txt')\n",
    "logger = setup_logger(\"logger:train\", summary_path, get_rank(), filename=\"logger_maskrcn-style.txt\")\n",
    "logger.info(colored(\"==[config]== opt\", 'white', 'on_blue'))\n",
    "logger.info(opt)\n",
    "logger.info(colored(\"==[config]== cfg\", 'white', 'on_blue'))\n",
    "logger.info(cfg)\n",
    "logger.info(colored(\"==[config]== Loaded configuration file {}\".format(opt.config_file), 'white', 'on_blue'))\n",
    "with open(opt.config_file, \"r\") as cf:\n",
    "    config_str = \"\\n\" + cf.read()\n",
    "    logger.info(config_str)\n",
    "printer = printer(get_rank(), debug=opt.debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resume_task_name = '1109-0141-mm1_SUN360RCNN-HorizonPitchRollVfovNET_myDistNarrowerLarge1105_bs16on4_le1e-5_indeptClsHeads_synBNApex_valBS1_yannickTransformAug'\n",
    "\n",
    "model = RCNN_only(cfg, opt, logger, printer, rank=rank)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.SOLVER.BASE_LR, betas=(opt.beta1, 0.999), eps=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=20, cooldown=10)\n",
    "\n",
    "save_to_disk = get_rank() == 0\n",
    "# opt.checkpoints_folder = 'checkpoint'\n",
    "# checkpointer = DetectronCheckpointer(\n",
    "#     opt, model, optimizer, scheduler, opt.checkpoints_folder, os.path.join(opt.checkpoints_folder, resume_task_name), save_to_disk, logger=logger\n",
    "# )\n",
    "# checkpoint_restored, _, _ = checkpointer.load(task_name=resume_task_name)\n",
    "\n",
    "# === DATASET\n",
    "train_trnfs_maskrcnn = build_transforms_maskrcnn(cfg, True)\n",
    "eval_trnfs_maskrcnn = build_transforms_maskrcnn(cfg, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from dataset_cvpr import bins2roll, bins2vfov, bins2horizon, bins2pitch\n",
    "\n",
    "def showHorizonLine(image, vfov, pitch, roll, focal_length=-1, color=(0, 255, 0), width=5, debug=False, GT=False):\n",
    "    \"\"\"\n",
    "    Angles should be in radians.\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "    if image.dtype in (np.float32, np.float64):\n",
    "        image = (image * 255).astype('uint8')\n",
    "\n",
    "    if debug:\n",
    "        if GT == False:\n",
    "            image[0:12,:,:] = 0\n",
    "        else:\n",
    "            image[h-12:h,:,:] = 0\n",
    "\n",
    "    im = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    ctr = h*( 0.5 - 0.5*np.tan(pitch) / np.tan(vfov/2) )\n",
    "    l = ctr - w*np.tan(roll)/2\n",
    "    r = ctr + w*np.tan(roll)/2\n",
    "    if debug:\n",
    "        if GT == False:\n",
    "            draw.text((0, 0), \"vfov:{0:.2f}, pitch:{1:.2f}, roll:{2:.2f}, f_mm:{3:.2f}\".format(vfov*180/np.pi, pitch*180/np.pi, roll*180/np.pi, focal_length), (255, 255, 255))\n",
    "        else:\n",
    "            draw.text((0, h-12), \"GT: vfov:{0:.2f}, pitch:{1:.2f}, roll:{2:.2f}, f_mm:{3:.2f}\".format(vfov*180/np.pi, pitch*180/np.pi, roll*180/np.pi, focal_length), (255, 255, 255))\n",
    "\n",
    "    draw.line((0, l, w, r), fill=color, width=width)\n",
    "    return np.array(im), ctr/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() #很关键！\n",
    "\n",
    "test_image_path = 'demo/fall-cmu-700x700.jpg'\n",
    "# test_image_path = 'demo/white-house.jpg'\n",
    "im_ori_RGB = Image.open(test_image_path).convert('RGB') #im_ori_RGB.size: [W, H]\n",
    "im = eval_trnfs_maskrcnn(im_ori_RGB)\n",
    "        \n",
    "H_num, W_num = im_ori_RGB.size\n",
    "list_of_oneLargeBbox_list_cpu = model_utils.oneLargeBboxList([W_num], [H_num])\n",
    "list_of_oneLargeBbox_list = [bbox_list_array.to(device) for bbox_list_array in list_of_oneLargeBbox_list_cpu]\n",
    "\n",
    "output_RCNN = model(image_batch_list=[im.to(device)], list_of_oneLargeBbox_list=list_of_oneLargeBbox_list)\n",
    "output_horizon = output_RCNN['output_horizon']\n",
    "output_pitch = output_RCNN['output_pitch']\n",
    "output_roll = output_RCNN['output_roll']\n",
    "output_vfov = output_RCNN['output_vfov']\n",
    "\n",
    "idx = 0\n",
    "\n",
    "im = im_ori_RGB\n",
    "if len(im.getbands()) == 1:\n",
    "    im = Image.fromarray(np.tile(np.asarray(im)[:,:,np.newaxis], (1, 1, 3)))\n",
    "\n",
    "horizon_disc = output_horizon[idx].detach().cpu().numpy().squeeze()\n",
    "pitch_disc = output_pitch[idx].detach().cpu().numpy().squeeze()\n",
    "roll_disc = output_roll[idx].detach().cpu().numpy().squeeze()\n",
    "vfov_disc = output_vfov[idx].detach().cpu().numpy().squeeze()\n",
    "# distortion_disc = distortion_disc.detach().cpu().numpy().squeeze()\n",
    "vfov_disc[...,0] = -35\n",
    "vfov_disc[...,-1] = -35\n",
    "\n",
    "horizon = bins2horizon(horizon_disc)\n",
    "pitch = bins2pitch(pitch_disc)\n",
    "roll = bins2roll(roll_disc)\n",
    "vfov = bins2vfov(vfov_disc)\n",
    "w, h = im.size\n",
    "f_pix = h / 2. / np.tan(vfov / 2.)\n",
    "# sensor_size = sensor_size_num[idx]\n",
    "sensor_size = 24 # !!!!!!\n",
    "f_mm = f_pix / h * sensor_size\n",
    "# print(sensor_size)\n",
    "\n",
    "im2, _ = showHorizonLine(np.asarray(im).copy(), vfov, pitch, roll, focal_length=f_mm, debug=True, color=(0, 0, 255), width=3) # Blue: horizon converted from camera params with roll\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(im2)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

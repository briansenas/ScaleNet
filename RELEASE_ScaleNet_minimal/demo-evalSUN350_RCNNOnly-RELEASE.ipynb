{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "# current_dir = '/home/ruizhu/Documents/Projects/adobe_rui_camera-calibration-redux/adobe_camera_calibration_cvpr18'\n",
    "# parent_dir = '/home/ruizhu/Documents/Projects/adobe_rui_camera-calibration-redux'\n",
    "sys.path.insert(0, current_dir)\n",
    "# sys.path.insert(0, parent_dir)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import MultiStepLR, ReduceLROnPlateau\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "from models.model_RCNN_only import RCNN_only\n",
    "from dataset_cvpr import SUN360Horizon, pitch_bins_centers, roll_bins_centers, vfov_bins_centers, my_collate_SUN360\n",
    "from utils.compute_vectors import generate_field\n",
    "from maskrcnn_rui.data.transforms import build_transforms_maskrcnn, build_transforms_yannick\n",
    "\n",
    "from maskrcnn_rui.config import cfg\n",
    "\n",
    "from eval_epoch_cvpr_RCNN import eval_epoch_cvpr_RCNN\n",
    "import utils.model_utils as model_utils\n",
    "from utils.logger import setup_logger, printer\n",
    "from utils.train_utils import *\n",
    "from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n",
    "from utils.checkpointer import DetectronCheckpointer\n",
    "\n",
    "from utils.data_utils import make_data_loader, train_trnfs_yannick, eval_trnfs_yannick\n",
    "import maskrcnn_benchmark\n",
    "\n",
    "from utils.eval_save_utils_combine_RCNNONly import check_save\n",
    "from utils.utils_misc import *\n",
    "import utils.vis_utils as vis_utils\n",
    "# import apex\n",
    "\n",
    "from utils.eval_save_utils_combine_RCNNONly import check_vis_SUN360\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Rui's Scale Estimation Network Training\")\n",
    "# Training\n",
    "parser.add_argument('--task_name', type=str, default='tmp', help='resume training')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=8)\n",
    "parser.add_argument('--batchsize', type=int, default=36, help='input batch size during training')\n",
    "parser.add_argument('--save_every_iter', type=int, default=0, help='set to 0 to save ONLY at the end of each epoch')\n",
    "# parser.add_argument('--batchsizeeval', type=int, default=42, help='input batch size during evaluation')\n",
    "parser.add_argument('--niter', type=int, default=5000, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate, default=0.005')\n",
    "parser.add_argument('--beta1', type=float, default=0.9, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--not_val', action='store_true', help='Do not validate duruign training')\n",
    "parser.add_argument('--save_every_epoch', type=int, default=10, help='save checkpoint every ? epoch')\n",
    "# Model\n",
    "parser.add_argument('--accu_model', action='store_true', help='Use accurate model with theta instead of Derek\\'s approx.')\n",
    "# Pretraining\n",
    "parser.add_argument('--resume', type=str, help='resume training; can be full path (e.g. tmp/checkpoint0.pth.tar) or taskname (e.g. tmp)', default='NoCkpt')\n",
    "parser.add_argument('--feature_only', action='store_true', help='restore only features (remove all classifiers) from checkpoint')\n",
    "# Device\n",
    "parser.add_argument('--cpu', action='store_true', help='Force training on CPU')\n",
    "parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "parser.add_argument(\"--master_port\", type=str, default='8914')\n",
    "# DEBUG\n",
    "parser.add_argument('--debug', action='store_true', help='Debug eval')\n",
    "# Mask R-CNN\n",
    "parser.add_argument('--not_rcnn', action='store_true', help='Disable Mask R-CNN module')\n",
    "\n",
    "parser.add_argument('--pointnet_camH', action='store_true', help='')\n",
    "parser.add_argument('--est_bbox', action='store_true', help='Enable estimating bboxes instead of using GT bboxes')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--config-file\",\n",
    "    default=\"\",\n",
    "    metavar=\"FILE\",\n",
    "    help=\"path to config file\",\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"opts\",\n",
    "    help=\"Modify config options using the command-line\",\n",
    "    default=None,\n",
    "    nargs=argparse.REMAINDER,\n",
    ")\n",
    "\n",
    "# opt = parser.parse_args()\n",
    "opt = parser.parse_args('--batchsize=1 --task_name tmp_eval --niter 1 --accu_model --resume YES \\\n",
    "--config-file coco_config_small_RCNNOnly.yaml \\\n",
    "SOLVER.IMS_PER_BATCH 1 TEST.IMS_PER_BATCH 1'.split())\n",
    "\n",
    "opt.checkpoints_folder = 'checkpoint'\n",
    "\n",
    "# config_file = \"maskrcnn/coco_config.yaml\"\n",
    "config_file = opt.config_file\n",
    "cfg.merge_from_file(config_file)\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cuda\"])\n",
    "cfg.merge_from_list(opt.opts)\n",
    "cfg.freeze()\n",
    "opt.cfg = cfg\n",
    "\n",
    "# === DISTRIBUTED TRAINING\n",
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "opt.distributed = num_gpus > 1\n",
    "if opt.distributed:\n",
    "    torch.cuda.set_device(opt.local_rank)\n",
    "    torch.distributed.init_process_group(\n",
    "        backend=\"nccl\", init_method=\"env://\"\n",
    "    )\n",
    "    synchronize()\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() and not opt.cpu else \"cpu\")\n",
    "device = 'cuda'\n",
    "print(\"Device:\", device)\n",
    "rank = get_rank()\n",
    "\n",
    "# === SUMMARY WRITERS\n",
    "summary_path = './summary/'+opt.task_name\n",
    "writer = SummaryWriter(summary_path)\n",
    "\n",
    "# === LOGGING\n",
    "# sys.stdout = Logger(summary_path+'/log.txt')\n",
    "logger = setup_logger(\"logger:train\", summary_path, get_rank(), filename=\"logger_maskrcn-style.txt\")\n",
    "logger.info(colored(\"==[config]== opt\", 'white', 'on_blue'))\n",
    "logger.info(opt)\n",
    "logger.info(colored(\"==[config]== cfg\", 'white', 'on_blue'))\n",
    "logger.info(cfg)\n",
    "logger.info(colored(\"==[config]== Loaded configuration file {}\".format(opt.config_file), 'white', 'on_blue'))\n",
    "with open(opt.config_file, \"r\") as cf:\n",
    "    config_str = \"\\n\" + cf.read()\n",
    "    logger.info(config_str)\n",
    "printer = printer(get_rank(), debug=opt.debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_task_name = '1109-0141-mm1_SUN360RCNN-HorizonPitchRollVfovNET_myDistNarrowerLarge1105_bs16on4_le1e-5_indeptClsHeads_synBNApex_valBS1_yannickTransformAug'\n",
    "\n",
    "model = RCNN_only(cfg, opt, logger, printer, rank=rank)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.SOLVER.BASE_LR, betas=(opt.beta1, 0.999), eps=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=20, cooldown=10)\n",
    "\n",
    "save_to_disk = get_rank() == 0\n",
    "opt.checkpoints_folder = current_dir + '/checkpoint'\n",
    "checkpointer = DetectronCheckpointer(\n",
    "    opt, model, optimizer, scheduler, opt.checkpoints_folder, os.path.join(opt.checkpoints_folder, resume_task_name), save_to_disk, logger=logger\n",
    ")\n",
    "checkpoint_restored, _, _ = checkpointer.load(task_name=resume_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATASET\n",
    "# from dataset import COCO2017Scale\n",
    "from dataset_coco_pickle_eccv import COCO2017Scale, my_collate\n",
    "from maskrcnn_rui.data.transforms import build_transforms_maskrcnn, build_transforms_yannick\n",
    "\n",
    "# train_trnfs_maskrcnn = build_transforms_maskrcnn(cfg, True)\n",
    "# eval_trnfs_maskrcnn = build_transforms_maskrcnn(cfg, False)\n",
    "train_trnfs_maskrcnn = build_transforms_yannick(cfg, True)\n",
    "eval_trnfs_maskrcnn = build_transforms_yannick(cfg, False)\n",
    "\n",
    "ds_train_SUN360 = SUN360Horizon(transforms=train_trnfs_maskrcnn, train=True, logger=logger)\n",
    "ds_eval_SUN360 = SUN360Horizon(transforms=eval_trnfs_maskrcnn, train=False, logger=logger)\n",
    "training_loader_SUN360 = make_data_loader(\n",
    "    cfg,\n",
    "    ds_train_SUN360,\n",
    "    is_train=True,\n",
    "    is_distributed=opt.distributed,\n",
    "    start_iter=0,\n",
    "    logger=logger,\n",
    "    collate_fn=my_collate_SUN360,\n",
    "    override_shuffle=False,\n",
    ")\n",
    "eval_loader_SUN360 = make_data_loader(cfg, ds_eval_SUN360, is_train=False, is_distributed=opt.distributed, is_for_period=True, logger=logger, collate_fn=my_collate_SUN360, override_shuffle=False, batch_size_override=1)\n",
    "\n",
    "# ds_train_coco = COCO2017Scale(transforms_yannick=eval_trnfs_yannick, transforms_maskrcnn=eval_trnfs_maskrcnn, split='train', shuffle=False, logger=logger, opt=opt) # !!!!!!!\n",
    "# ds_eval_coco = COCO2017Scale(transforms_yannick=eval_trnfs_yannick, transforms_maskrcnn=eval_trnfs_maskrcnn, split='val', shuffle=False, logger=logger, opt=opt)\n",
    "# training_loader_coco = make_data_loader(\n",
    "#     cfg,\n",
    "#     ds_train_coco,\n",
    "#     is_train=True,\n",
    "#     is_distributed=opt.distributed,\n",
    "#     start_iter=0,\n",
    "#     logger=logger,\n",
    "#     override_shuffle=False,\n",
    "#     collate_fn=my_collate,\n",
    "# )\n",
    "# eval_loader_coco = make_data_loader(cfg, ds_eval_coco, is_train=False, is_distributed=opt.distributed, is_for_period=True, logger=logger, override_shuffle=False, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval SUN360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import skimage.io as io\n",
    "from matplotlib.patches import Rectangle\n",
    "import utils.utils_coco as utils_coco\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from imageio import imread, imsave\n",
    "\n",
    "from panorama_cropping_dataset_generation.debugging import drawLine, showHorizonLine, showHorizonLineFromHorizon\n",
    "from dataset_cvpr import bins2roll, bins2vfov, bins2horizon, bins2pitch\n",
    "from utils.model_utils import get_bins_combine\n",
    "\n",
    "\n",
    "test_loader = eval_loader_SUN360\n",
    "\n",
    "model.eval() #很关键！\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (im_paths_SUN360, inputSUN360_Image_yannickTransform_list, \\\n",
    "                horizon_dist_gt, pitch_dist_gt, roll_dist_gt, vfov_dist_gt, metadata, \\\n",
    "                pitch_num, roll_num, vfov_num, horizon_num, focal_length_35mm_eq_num, sensor_size_num, W_num, H_num, idx1, idx2, idx3, idx4) in enumerate(test_loader):\n",
    "\n",
    "        horizon_dist_gt, pitch_dist_gt, roll_dist_gt, vfov_dist_gt = horizon_dist_gt.to(device), pitch_dist_gt.to(device), roll_dist_gt.to(device), vfov_dist_gt.to(device)\n",
    "        \n",
    "        list_of_oneLargeBbox_list_cpu = model_utils.oneLargeBboxList(W_num, H_num)\n",
    "        list_of_oneLargeBbox_list = [bbox_list_array.to(device) for bbox_list_array in list_of_oneLargeBbox_list_cpu]\n",
    "\n",
    "        output_RCNN = model(image_batch_list=inputSUN360_Image_yannickTransform_list, list_of_oneLargeBbox_list=list_of_oneLargeBbox_list)\n",
    "        output_horizon = output_RCNN['output_horizon']\n",
    "        output_pitch = output_RCNN['output_pitch']\n",
    "        output_roll = output_RCNN['output_roll']\n",
    "        output_vfov = output_RCNN['output_vfov']\n",
    "\n",
    "        idx = 0\n",
    "        assert len(im_paths_SUN360)==1, 'len of im_paths_SUN360 is %d'%len(im_paths_SUN360)\n",
    "\n",
    "        im = Image.fromarray(imread(im_paths_SUN360[idx])[:,:,:3])\n",
    "        if len(im.getbands()) == 1:\n",
    "            im = Image.fromarray(np.tile(np.asarray(im)[:,:,np.newaxis], (1, 1, 3)))\n",
    "\n",
    "        horizon_disc = output_horizon[idx].detach().cpu().numpy().squeeze()\n",
    "        pitch_disc = output_pitch[idx].detach().cpu().numpy().squeeze()\n",
    "        roll_disc = output_roll[idx].detach().cpu().numpy().squeeze()\n",
    "        vfov_disc = output_vfov[idx].detach().cpu().numpy().squeeze()\n",
    "        # distortion_disc = distortion_disc.detach().cpu().numpy().squeeze()\n",
    "        vfov_disc[...,0] = -35\n",
    "        vfov_disc[...,-1] = -35\n",
    "\n",
    "        horizon = bins2horizon(horizon_disc)\n",
    "        pitch = bins2pitch(pitch_disc)\n",
    "        roll = bins2roll(roll_disc)\n",
    "        vfov = bins2vfov(vfov_disc)\n",
    "        h, w = im.size\n",
    "        f_pix = h / 2. / np.tan(vfov / 2.)\n",
    "        sensor_size = sensor_size_num[idx]\n",
    "        # sensor_size = 24 # !!!!!!\n",
    "        f_mm = f_pix / h * sensor_size\n",
    "        print(sensor_size)\n",
    "\n",
    "        # horizon_from_pitch = 0.5 - 0.5*np.tan(pitch) / np.tan(vfov/2)\n",
    "\n",
    "        im2, _ = showHorizonLine(np.asarray(im).copy(), vfov, pitch, roll, focal_length=f_mm, debug=True, color=(0, 0, 255), width=3) # Blue: horizon converted from camera params with roll\n",
    "#         im2, _ = showHorizonLine(im2, vfov, pitch, 0., focal_length=f_mm, debug=True, color=(0, 0, 255), width=4) # Blue: horizon converted from camera params with roll\n",
    "#         im2 = showHorizonLineFromHorizon(im2, horizon, color=(255, 255, 0), width=4) # Yellow: est horizon\n",
    "\n",
    "        horizon_gt = horizon_num[idx]\n",
    "        pitch_gt = pitch_num[idx]\n",
    "        roll_gt = roll_num[idx]\n",
    "        vfov_gt = vfov_num[idx]\n",
    "        f_gt = focal_length_35mm_eq_num[idx]\n",
    "#         im2 = showHorizonLineFromHorizon(im2, horizon_gt, color=(255, 255, 255), width=3) # White: GT horizon\n",
    "        im2, _ = showHorizonLine(im2, vfov_gt, pitch_gt, roll_gt, focal_length=f_gt, debug=False, color=(255, 255, 255), width=1) # White: GT horizon with roll\n",
    "\n",
    "#         if if_save:\n",
    "#             prefix, postfix = prepostfix.split('|')\n",
    "#             im_save_path = os.path.join(save_path, prefix+'tid%d-rank%d-idx%d'%(tid, rank, idx) + postfix + '-' +ntpath.basename(im_paths[idx])+'-f%.2f-GT%.2f.jpg'%(f_mm, f_gt))\n",
    "#             imsave(im_save_path, im2)\n",
    "#             print('Saved to ' + im_save_path)\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.imshow(im2)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        break\n",
    "#         if i > 3:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "test_image_path = 'demo/fall-cmu-700x700.jpg'\n",
    "im_ori_RGB = Image.open(test_image_path).convert('RGB') #im_ori_RGB.size: [W, H]\n",
    "im = eval_trnfs_maskrcnn(im_ori_RGB)\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, (im_paths_SUN360, inputSUN360_Image_yannickTransform_list, \\\n",
    "#                 horizon_dist_gt, pitch_dist_gt, roll_dist_gt, vfov_dist_gt, metadata, \\\n",
    "#                 pitch_num, roll_num, vfov_num, horizon_num, focal_length_35mm_eq_num, sensor_size_num, W_num, H_num, idx1, idx2, idx3, idx4) in enumerate(test_loader):\n",
    "\n",
    "#         horizon_dist_gt, pitch_dist_gt, roll_dist_gt, vfov_dist_gt = horizon_dist_gt.to(device), pitch_dist_gt.to(device), roll_dist_gt.to(device), vfov_dist_gt.to(device)\n",
    "        \n",
    "H_num, W_num = im_ori_RGB.size\n",
    "list_of_oneLargeBbox_list_cpu = model_utils.oneLargeBboxList([W_num], [H_num])\n",
    "list_of_oneLargeBbox_list = [bbox_list_array.to(device) for bbox_list_array in list_of_oneLargeBbox_list_cpu]\n",
    "\n",
    "output_RCNN = model(image_batch_list=[im.to(device)], list_of_oneLargeBbox_list=list_of_oneLargeBbox_list)\n",
    "output_horizon = output_RCNN['output_horizon']\n",
    "output_pitch = output_RCNN['output_pitch']\n",
    "output_roll = output_RCNN['output_roll']\n",
    "output_vfov = output_RCNN['output_vfov']\n",
    "\n",
    "idx = 0\n",
    "assert len(im_paths_SUN360)==1, 'len of im_paths_SUN360 is %d'%len(im_paths_SUN360)\n",
    "\n",
    "# im = Image.fromarray(imread(im_paths_SUN360[idx])[:,:,:3])\n",
    "im = im_ori_RGB\n",
    "if len(im.getbands()) == 1:\n",
    "    im = Image.fromarray(np.tile(np.asarray(im)[:,:,np.newaxis], (1, 1, 3)))\n",
    "\n",
    "horizon_disc = output_horizon[idx].detach().cpu().numpy().squeeze()\n",
    "pitch_disc = output_pitch[idx].detach().cpu().numpy().squeeze()\n",
    "roll_disc = output_roll[idx].detach().cpu().numpy().squeeze()\n",
    "vfov_disc = output_vfov[idx].detach().cpu().numpy().squeeze()\n",
    "# distortion_disc = distortion_disc.detach().cpu().numpy().squeeze()\n",
    "vfov_disc[...,0] = -35\n",
    "vfov_disc[...,-1] = -35\n",
    "\n",
    "horizon = bins2horizon(horizon_disc)\n",
    "pitch = bins2pitch(pitch_disc)\n",
    "roll = bins2roll(roll_disc)\n",
    "vfov = bins2vfov(vfov_disc)\n",
    "h, w = im.size\n",
    "f_pix = h / 2. / np.tan(vfov / 2.)\n",
    "sensor_size = sensor_size_num[idx]\n",
    "# sensor_size = 24 # !!!!!!\n",
    "f_mm = f_pix / h * sensor_size\n",
    "print(sensor_size)\n",
    "\n",
    "# horizon_from_pitch = 0.5 - 0.5*np.tan(pitch) / np.tan(vfov/2)\n",
    "\n",
    "im2, _ = showHorizonLine(np.asarray(im).copy(), vfov, pitch, roll, focal_length=f_mm, debug=True, color=(0, 0, 255), width=3) # Blue: horizon converted from camera params with roll\n",
    "#         im2, _ = showHorizonLine(im2, vfov, pitch, 0., focal_length=f_mm, debug=True, color=(0, 0, 255), width=4) # Blue: horizon converted from camera params with roll\n",
    "#         im2 = showHorizonLineFromHorizon(im2, horizon, color=(255, 255, 0), width=4) # Yellow: est horizon\n",
    "\n",
    "# horizon_gt = horizon_num[idx]\n",
    "# pitch_gt = pitch_num[idx]\n",
    "# roll_gt = roll_num[idx]\n",
    "# vfov_gt = vfov_num[idx]\n",
    "# f_gt = focal_length_35mm_eq_num[idx]\n",
    "# #         im2 = showHorizonLineFromHorizon(im2, horizon_gt, color=(255, 255, 255), width=3) # White: GT horizon\n",
    "# im2, _ = showHorizonLine(im2, vfov_gt, pitch_gt, roll_gt, focal_length=f_gt, debug=False, color=(255, 255, 255), width=1) # White: GT horizon with roll\n",
    "\n",
    "#         if if_save:\n",
    "#             prefix, postfix = prepostfix.split('|')\n",
    "#             im_save_path = os.path.join(save_path, prefix+'tid%d-rank%d-idx%d'%(tid, rank, idx) + postfix + '-' +ntpath.basename(im_paths[idx])+'-f%.2f-GT%.2f.jpg'%(f_mm, f_gt))\n",
    "#             imsave(im_save_path, im2)\n",
    "#             print('Saved to ' + im_save_path)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(im2)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# break\n",
    "#         if i > 3:\n",
    "#             break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scalenet] *",
   "language": "python",
   "name": "conda-env-scalenet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

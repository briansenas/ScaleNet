{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import os, sys, inspect\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, current_dir)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "from models.model_RCNN_only import RCNN_only\n",
    "from dataset_cvpr import SUN360Horizon, my_collate_SUN360\n",
    "\n",
    "from maskrcnn_rui.config import cfg\n",
    "\n",
    "import utils.model_utils as model_utils\n",
    "from utils.logger import setup_logger, printer\n",
    "from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n",
    "from utils.checkpointer import DetectronCheckpointer\n",
    "\n",
    "from utils.data_utils import make_data_loader\n",
    "from utils.train_utils import *\n",
    "from utils.utils_misc import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Rui's Scale Estimation Network Training\")\n",
    "# Training\n",
    "parser.add_argument(\"--task_name\", type=str, default=\"tmp\", help=\"resume training\")\n",
    "parser.add_argument(\n",
    "    \"--workers\", type=int, help=\"number of data loading workers\", default=8\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batchsize\", type=int, default=36, help=\"input batch size during training\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_every_iter\",\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help=\"set to 0 to save ONLY at the end of each epoch\",\n",
    ")\n",
    "# parser.add_argument('--batchsizeeval', type=int, default=42, help='input batch size during evaluation')\n",
    "parser.add_argument(\n",
    "    \"--niter\", type=int, default=5000, help=\"number of epochs to train for\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr\", type=float, default=1e-3, help=\"learning rate, default=0.005\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta1\", type=float, default=0.9, help=\"beta1 for adam. default=0.5\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--not_val\", action=\"store_true\", help=\"Do not validate duruign training\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_every_epoch\", type=int, default=10, help=\"save checkpoint every ? epoch\"\n",
    ")\n",
    "# Model\n",
    "parser.add_argument(\n",
    "    \"--accu_model\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Use accurate model with theta instead of Derek's approx.\",\n",
    ")\n",
    "# Pretraining\n",
    "parser.add_argument(\n",
    "    \"--resume\",\n",
    "    type=str,\n",
    "    help=\"resume training; can be full path (e.g. tmp/checkpoint0.pth.tar) or taskname (e.g. tmp)\",\n",
    "    default=\"NoCkpt\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--feature_only\",\n",
    "    action=\"store_true\",\n",
    "    help=\"restore only features (remove all classifiers) from checkpoint\",\n",
    ")\n",
    "# Device\n",
    "parser.add_argument(\"--cpu\", action=\"store_true\", help=\"Force training on CPU\")\n",
    "parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "parser.add_argument(\"--master_port\", type=str, default=\"8914\")\n",
    "# DEBUG\n",
    "parser.add_argument(\"--debug\", action=\"store_true\", help=\"Debug eval\")\n",
    "# Mask R-CNN\n",
    "parser.add_argument(\"--not_rcnn\", action=\"store_true\", help=\"Disable Mask R-CNN module\")\n",
    "\n",
    "parser.add_argument(\"--pointnet_camH\", action=\"store_true\", help=\"\")\n",
    "parser.add_argument(\n",
    "    \"--est_bbox\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Enable estimating bboxes instead of using GT bboxes\",\n",
    ")\n",
    "\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--config-file\",\n",
    "    default=\"\",\n",
    "    metavar=\"FILE\",\n",
    "    help=\"path to config file\",\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"opts\",\n",
    "    help=\"Modify config options using the command-line\",\n",
    "    default=None,\n",
    "    nargs=argparse.REMAINDER,\n",
    ")\n",
    "\n",
    "# opt = parser.parse_args()\n",
    "opt = parser.parse_args(\n",
    "    \"--batchsize=1 --task_name tmp_eval --niter 1 --accu_model --resume YES \\\n",
    "--config-file config/coco_config_small_RCNNOnly.yaml \\\n",
    "SOLVER.IMS_PER_BATCH 1 TEST.IMS_PER_BATCH 1\".split()\n",
    ")\n",
    "\n",
    "opt.checkpoints_folder = \"checkpoint\"\n",
    "\n",
    "# config_file = \"maskrcnn/coco_config.yaml\"\n",
    "config_file = opt.config_file\n",
    "cfg.merge_from_file(config_file)\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cuda\"])\n",
    "cfg.merge_from_list(opt.opts)\n",
    "cfg.freeze()\n",
    "opt.cfg = cfg\n",
    "\n",
    "# === DISTRIBUTED TRAINING\n",
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "opt.distributed = num_gpus > 1\n",
    "if opt.distributed:\n",
    "    torch.cuda.set_device(opt.local_rank)\n",
    "    torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    synchronize()\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() and not opt.cpu else \"cpu\")\n",
    "device = \"cuda\"\n",
    "print(\"Device:\", device)\n",
    "rank = get_rank()\n",
    "\n",
    "# === SUMMARY WRITERS\n",
    "summary_path = \"./summary/\" + opt.task_name\n",
    "writer = SummaryWriter(summary_path)\n",
    "\n",
    "# === LOGGING\n",
    "# sys.stdout = Logger(summary_path+'/log.txt')\n",
    "logger = setup_logger(\n",
    "    \"logger:train\", summary_path, get_rank(), filename=\"logger_maskrcn-style.txt\"\n",
    ")\n",
    "logger.info(colored(\"==[config]== opt\", \"white\", \"on_blue\"))\n",
    "logger.info(opt)\n",
    "logger.info(colored(\"==[config]== cfg\", \"white\", \"on_blue\"))\n",
    "logger.info(cfg)\n",
    "logger.info(\n",
    "    colored(\n",
    "        \"==[config]== Loaded configuration file {}\".format(opt.config_file),\n",
    "        \"white\",\n",
    "        \"on_blue\",\n",
    "    )\n",
    ")\n",
    "with open(opt.config_file, \"r\") as cf:\n",
    "    config_str = \"\\n\" + cf.read()\n",
    "    logger.info(config_str)\n",
    "printer = printer(get_rank(), debug=opt.debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_task_name = \"1109-0141-mm1_SUN360RCNN-HorizonPitchRollVfovNET_myDistNarrowerLarge1105_bs16on4_le1e-5_indeptClsHeads_synBNApex_valBS1_yannickTransformAug\"\n",
    "\n",
    "model = RCNN_only(cfg, opt, logger, printer, rank=rank)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=cfg.SOLVER.BASE_LR, betas=(opt.beta1, 0.999), eps=1e-5\n",
    ")\n",
    "scheduler = ReduceLROnPlateau(optimizer, \"min\", factor=0.1, patience=20, cooldown=10)\n",
    "\n",
    "save_to_disk = get_rank() == 0\n",
    "opt.checkpoints_folder = current_dir + \"/checkpoint\"\n",
    "checkpointer = DetectronCheckpointer(\n",
    "    opt,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    opt.checkpoints_folder,\n",
    "    os.path.join(opt.checkpoints_folder, resume_task_name),\n",
    "    save_to_disk,\n",
    "    logger=logger,\n",
    ")\n",
    "checkpoint_restored, _, _ = checkpointer.load(task_name=resume_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_rui.data.transforms import (\n",
    "    build_transforms_yannick,\n",
    ")\n",
    "eval_trnfs_maskrcnn = build_transforms_yannick(cfg, False)\n",
    "ds_eval_SUN360 = SUN360Horizon(\n",
    "    transforms=eval_trnfs_maskrcnn, train=False, logger=logger\n",
    ")\n",
    "eval_loader_SUN360 = make_data_loader(\n",
    "    cfg,\n",
    "    ds_eval_SUN360,\n",
    "    is_train=False,\n",
    "    is_distributed=opt.distributed,\n",
    "    is_for_period=True,\n",
    "    logger=logger,\n",
    "    collate_fn=my_collate_SUN360,\n",
    "    override_shuffle=False,\n",
    "    batch_size_override=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval SUN360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "\n",
    "from panorama_cropping_dataset_generation.debugging import showHorizonLine\n",
    "from dataset_cvpr import bins2roll, bins2vfov, bins2horizon, bins2pitch\n",
    "\n",
    "\n",
    "test_loader = eval_loader_SUN360\n",
    "\n",
    "model.eval()  # 很关键！\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (\n",
    "        im_paths_SUN360,\n",
    "        inputSUN360_Image_yannickTransform_list,\n",
    "        horizon_dist_gt,\n",
    "        pitch_dist_gt,\n",
    "        roll_dist_gt,\n",
    "        vfov_dist_gt,\n",
    "        metadata,\n",
    "        pitch_num,\n",
    "        roll_num,\n",
    "        vfov_num,\n",
    "        horizon_num,\n",
    "        focal_length_35mm_eq_num,\n",
    "        sensor_size_num,\n",
    "        W_num,\n",
    "        H_num,\n",
    "        idx1,\n",
    "        idx2,\n",
    "        idx3,\n",
    "        idx4,\n",
    "    ) in enumerate(test_loader):\n",
    "\n",
    "        horizon_dist_gt, pitch_dist_gt, roll_dist_gt, vfov_dist_gt = (\n",
    "            horizon_dist_gt.to(device),\n",
    "            pitch_dist_gt.to(device),\n",
    "            roll_dist_gt.to(device),\n",
    "            vfov_dist_gt.to(device),\n",
    "        )\n",
    "\n",
    "        list_of_oneLargeBbox_list_cpu = model_utils.oneLargeBboxList(W_num, H_num)\n",
    "        list_of_oneLargeBbox_list = [\n",
    "            bbox_list_array.to(device)\n",
    "            for bbox_list_array in list_of_oneLargeBbox_list_cpu\n",
    "        ]\n",
    "\n",
    "        output_RCNN = model(\n",
    "            image_batch_list=inputSUN360_Image_yannickTransform_list,\n",
    "            list_of_oneLargeBbox_list=list_of_oneLargeBbox_list,\n",
    "        )\n",
    "        output_horizon = output_RCNN[\"output_horizon\"]\n",
    "        output_pitch = output_RCNN[\"output_pitch\"]\n",
    "        output_roll = output_RCNN[\"output_roll\"]\n",
    "        output_vfov = output_RCNN[\"output_vfov\"]\n",
    "\n",
    "        idx = 0\n",
    "        assert len(im_paths_SUN360) == 1, \"len of im_paths_SUN360 is %d\" % len(\n",
    "            im_paths_SUN360\n",
    "        )\n",
    "\n",
    "        im = Image.fromarray(imread(im_paths_SUN360[idx])[:, :, :3])\n",
    "        if len(im.getbands()) == 1:\n",
    "            im = Image.fromarray(np.tile(np.asarray(im)[:, :, np.newaxis], (1, 1, 3)))\n",
    "\n",
    "        horizon_disc = output_horizon[idx].detach().cpu().numpy().squeeze()\n",
    "        pitch_disc = output_pitch[idx].detach().cpu().numpy().squeeze()\n",
    "        roll_disc = output_roll[idx].detach().cpu().numpy().squeeze()\n",
    "        vfov_disc = output_vfov[idx].detach().cpu().numpy().squeeze()\n",
    "        # distortion_disc = distortion_disc.detach().cpu().numpy().squeeze()\n",
    "        vfov_disc[..., 0] = -35\n",
    "        vfov_disc[..., -1] = -35\n",
    "\n",
    "        horizon = bins2horizon(horizon_disc)\n",
    "        pitch = bins2pitch(pitch_disc)\n",
    "        roll = bins2roll(roll_disc)\n",
    "        vfov = bins2vfov(vfov_disc)\n",
    "        h, w = im.size\n",
    "        f_pix = h / 2.0 / np.tan(vfov / 2.0)\n",
    "        sensor_size = sensor_size_num[idx]\n",
    "        # sensor_size = 24 # !!!!!!\n",
    "        f_mm = f_pix / h * sensor_size\n",
    "\n",
    "        im2, _ = showHorizonLine(\n",
    "            np.asarray(im).copy(),\n",
    "            vfov,\n",
    "            pitch,\n",
    "            roll,\n",
    "            focal_length=f_mm,\n",
    "            debug=True,\n",
    "            color=(0, 0, 255),\n",
    "            width=3,\n",
    "        )  # Blue: horizon converted from camera params with roll\n",
    "\n",
    "        horizon_gt = horizon_num[idx]\n",
    "        pitch_gt = pitch_num[idx]\n",
    "        roll_gt = roll_num[idx]\n",
    "        vfov_gt = vfov_num[idx]\n",
    "        f_gt = focal_length_35mm_eq_num[idx]\n",
    "        im2, _ = showHorizonLine(\n",
    "            im2,\n",
    "            vfov_gt,\n",
    "            pitch_gt,\n",
    "            roll_gt,\n",
    "            focal_length=f_gt,\n",
    "            debug=False,\n",
    "            color=(255, 255, 255),\n",
    "            width=1,\n",
    "        )  # White: GT horizon with roll\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.imshow(im2)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
